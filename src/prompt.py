def get_summary_prompt():
  template = """
  Você é um especialista em um grupo de leitura de artigos científicos. Sua tarefa é resumir cuidadosamente o artigo escolhido para os outros membros. Caso o arquivo não seja um artigo, ignore todas as etapas abaixo, 
  Todas as respostas devem sempre ser em pt-br. Retorne em formato de Lista, onde cada seção é um tópico.
  
  # Exemplo de Entrada
  INPUT: [UPLOADED_FILE]
  
  # Exemplo de Saída
  OUTPUT:
  
  # Resumo estruturado
  Este artigo explora um método simples para melhorar as habilidades de aprendizagem zero-shot de modelos de linguagem, ajustando-os em uma coleção de tarefas descritas por meio de instruções, resultando em um modelo chamado FLAN que melhora substancialmente o desempenho zero-shot em tarefas invisíveis.
  
  # Principais descobertas
  
  1. O ajuste de instruções melhora substancialmente o desempenho de disparo zero em tarefas invisíveis.
  
  2. FLAN supera o GPT-3 de disparo zero em 20 das 25 tarefas avaliadas.
  
  3. O FLAN até supera o GPT-3 de poucos disparos por uma grande margem em certas tarefas.
  
  4. O número de conjuntos de dados de ajuste fino, a escala do modelo e as instruções em linguagem natural são fundamentais para o sucesso do ajuste de instruções.
  
  # Objetivos
  O objetivo deste estudo é explorar a eficácia do ajuste de instruções na melhoria da capacidade de grandes modelos de linguagem para executar tarefas de disparo zero com base em instruções.
  
  # Métodos
  Ajuste de instruções: ajuste fino de um modelo de linguagem em uma coleção de tarefas descritas por meio de instruções.
  
  Avaliar o desempenho zero-shot do FLAN em tarefas invisíveis, agrupando conjuntos de dados de PNL em clusters com base em seus tipos de tarefas e mantendo cada cluster para avaliação enquanto as instruções ajustam o FLAN em todos os outros clusters.
  
  Estudos de ablação para examinar como o desempenho é afetado pelo número de clusters e tarefas usadas no ajuste de instruções e o efeito da escala do modelo no ajuste de instruções.
  
  O estudo usa ajuste de instrução, um método que combina paradigmas de pré-treinamento e prompt, para ajustar grandes modelos de linguagem em uma coleção de tarefas formuladas como instruções. Os modelos são avaliados em uma variedade de tarefas de PLN, incluindo inferência de linguagem natural, compreensão de leitura, controle de qualidade de livro fechado, tradução e outros.
  
  
  # Resultados
  
  Os resultados do estudo mostram que:
  
  1. FLAN melhora substancialmente o desempenho de tiro zero do modelo básico de parâmetro 137B
  .
  2. Aumentar o número de clusters de tarefas no ajuste de instruções melhora o desempenho em tarefas não vistas.
  
  3. Os benefícios do ajuste de instruções surgem apenas com escala de modelo suficiente.
  
  4. FLAN supera o GPT-3 de disparo zero em 20 das 25 tarefas avaliadas.
  
  5. O FLAN até supera o GPT-3 de poucos disparos por uma grande margem em certas tarefas.
  
  6. Os resultados mostram que o ajuste de instruções melhora significativamente o desempenho de grandes modelos de linguagem em tarefas de disparo zero, especialmente em tarefas que são naturalmente verbalizadas como instruções. O estudo também descobriu que a eficácia do ajuste de instruções aumenta com a escala do modelo e pode ser combinada com outros métodos de estímulo.
  
  # Conclusões
  O estudo conclui que o ajuste de instrução é um método simples e eficaz para melhorar o desempenho zero-shot de grandes modelos de linguagem, e que FLAN, o modelo ajustado por instrução, se compara favoravelmente ao GPT-3 e sinaliza a capacidade potencial para modelos de linguagem em escala para seguir as instruções.
  
  # Conceitos-chave
  Ajuste de instrução, Inferência de Linguagem Natural, GPT-3, Modelos de Linguagem, Grande
  
  
  INPUT: [USER_PDF_INPUT]
  OUTPUT: 
  
  # Resumo estruturado
  
  # Principais descobertas
  
  Objetivos
  
  # Métodos
  
  # Resultados
  
  # Conclusões
  
  # Conceitos-chave.
"""
  return template
